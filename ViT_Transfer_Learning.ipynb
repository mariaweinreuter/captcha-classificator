{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6kr8Q191ylV"
      },
      "source": [
        "### Transfer Learning using ViT Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJtx_Glm1n1d"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjhkdLQE1-h1"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFVV6out2U98"
      },
      "source": [
        "### Step 1: Define Image Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1LmWMqz2SsR"
      },
      "outputs": [],
      "source": [
        "# Prepare and augment data for ViT model\n",
        "train_val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # because ViT was trained on images with this resolution\n",
        "    transforms.RandomHorizontalFlip(), # common data augmentation\n",
        "    #transforms.RandomRotation(15),\n",
        "    #transforms.RandomCrop(224, padding=10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # specific standardization for ViT\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize for test\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2cCe1Uh2rBU"
      },
      "source": [
        "### Step 2: Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZdpqBYw2-fJ",
        "outputId": "db380602-83e2-4527-91ad-3f4851eaad1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdZUHfM12v3L",
        "outputId": "2c5f492f-39a4-4cbf-be15-b0fc7527ff9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 12\n"
          ]
        }
      ],
      "source": [
        "root = \"/content/drive/MyDrive/\"\n",
        "train_val_folder = root + \"train_val_data/\"\n",
        "\n",
        "# Use ImageFolder to load the dataset\n",
        "train_val_dataset = datasets.ImageFolder(train_val_folder, transform=train_val_transform)\n",
        "num_classes = len(train_val_dataset.classes)  # Number of classes in the dataset\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MjoTgF63Pc6"
      },
      "source": [
        "### Step 3: Split Data into Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5Cee-PL3Tbu"
      },
      "outputs": [],
      "source": [
        "train_percentage = 0.8\n",
        "train_size = int(train_percentage * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(\n",
        "    train_val_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drRFUC1r3hKR"
      },
      "source": [
        "### Step 4: DataLoaders for Efficient Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avamAMWE3e-F",
        "outputId": "26d89dc1-8cc3-45d8-af60-ba4d8239b3ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training images: 2400, Validation images: 600\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32  # Adjust based on GPU memory\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Training images: {len(train_dataset)}, Validation images: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dkXAzkB3rHm"
      },
      "source": [
        "### Step 5: ViT Model Definition\n",
        "\n",
        "Thereby, we freeze some layers for Transfer Learning:\n",
        "* freezing earlier layers retains general features learned on a large dataset (e.g., ImageNet)\n",
        "* we only fine-tune the later layers and the classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG_kmjjD3t4v"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained Vision Transformer from `timm` library\n",
        "def create_model(num_classes):\n",
        "    model = timm.create_model('vit_base_patch16_224', pretrained=True)  # Load ViT\n",
        "    # Freeze all layers initially\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    # Replace the classification head with a new one for our task\n",
        "    model.head = nn.Linear(model.head.in_features, num_classes)\n",
        "    # Unfreeze the final few layers for fine-tuning\n",
        "    for param in model.blocks[-2:].parameters():  # Unfreeze last two blocks\n",
        "        param.requires_grad = True\n",
        "    return model.to(device)\n",
        "\n",
        "model = create_model(num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpPM8XRg4FXb"
      },
      "source": [
        "### Step 6: Define Loss Function and Optimizer\n",
        "\n",
        "For AdamW optimizer, we adjust the learning rate for fine-tuning. Therefore, we\n",
        "* use a lower learning rate for the pre-trained layers (frozen or partially fine-tuned)\n",
        "* use a higher learning rate for the new classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL9zw7sF348J"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()  # Common multi-class classification loss\n",
        "optimizer = optim.AdamW([\n",
        "    {'params': model.head.parameters(), 'lr': 1e-3},  # Higher learning rate for the head\n",
        "    {'params': model.blocks[-2:].parameters(), 'lr': 1e-4}  # Lower learning rate for fine-tuned layers\n",
        "], weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_qPYDnN4Ps0"
      },
      "source": [
        "### Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hauj8gG-36QR"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=10):\n",
        "    best_val_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        #print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        model.train()  # Set the model to training mode\n",
        "        train_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            outputs = model(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)  # Get predicted classes\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_loss /= total\n",
        "        train_accuracy = 100 * correct / total\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        val_loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_loss /= total\n",
        "        val_accuracy = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "        # Save the best model\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(\"Best model saved.\")\n",
        "\n",
        "    print(f\"Best Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkrNcnXH4AeA",
        "outputId": "8685af47-40bd-4051-85da-f1261a0c4a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 0.6763, Train Acc: 78.25%, Val Loss: 0.4374, Val Acc: 86.33%\n",
            "Best model saved.\n",
            "Epoch 2/10, Train Loss: 0.2179, Train Acc: 92.33%, Val Loss: 0.5094, Val Acc: 84.50%\n",
            "Epoch 3/10, Train Loss: 0.1112, Train Acc: 96.29%, Val Loss: 0.6716, Val Acc: 85.00%\n",
            "Epoch 4/10, Train Loss: 0.0471, Train Acc: 98.21%, Val Loss: 0.7943, Val Acc: 86.17%\n",
            "Epoch 5/10, Train Loss: 0.0327, Train Acc: 99.04%, Val Loss: 0.7802, Val Acc: 86.00%\n",
            "Epoch 6/10, Train Loss: 0.0379, Train Acc: 98.75%, Val Loss: 0.8434, Val Acc: 83.33%\n",
            "Epoch 7/10, Train Loss: 0.0288, Train Acc: 99.17%, Val Loss: 0.8553, Val Acc: 86.33%\n",
            "Epoch 8/10, Train Loss: 0.0066, Train Acc: 99.92%, Val Loss: 0.8289, Val Acc: 87.00%\n",
            "Best model saved.\n",
            "Epoch 9/10, Train Loss: 0.0005, Train Acc: 100.00%, Val Loss: 0.8622, Val Acc: 87.17%\n",
            "Best model saved.\n",
            "Epoch 10/10, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.9033, Val Acc: 87.67%\n",
            "Best model saved.\n",
            "Best Validation Accuracy: 87.67%\n"
          ]
        }
      ],
      "source": [
        "model = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYBgNFFN6Jbr"
      },
      "source": [
        "### Step 8: Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ifa_RSZ6IYs"
      },
      "outputs": [],
      "source": [
        "def create_result_file(model, test_dataset, classes):\n",
        "\n",
        "    keys = [\"ImageName\", *classes]\n",
        "    prediction_dict = {key: [] for key in keys}\n",
        "    names = test_dataset.imgs\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for i in range(len(test_dataset)):\n",
        "        input = test_dataset.__getitem__(i)\n",
        "        input = input[0].to(device).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input).cpu().squeeze().numpy()\n",
        "            prediction_dict[\"ImageName\"].append(os.path.basename(names[i][0]))\n",
        "            for class_idx, class_name in enumerate(classes):\n",
        "                prediction_dict[class_name].append(outputs[class_idx])\n",
        "\n",
        "    df = pd.DataFrame.from_dict(prediction_dict)\n",
        "    df.to_csv(\"result2.csv\", index=False)\n",
        "    print(\"Results saved to result.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9RIFlGb7NVM"
      },
      "outputs": [],
      "source": [
        "# Load test dataset\n",
        "test_folder = root + \"test_folder/\"\n",
        "test_dataset = datasets.ImageFolder(test_folder, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0r259608RJc",
        "outputId": "932504f8-e451-4e74-e22c-f1d6f67cd8ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to result.csv\n"
          ]
        }
      ],
      "source": [
        "# Save predictions\n",
        "classes = train_val_dataset.classes\n",
        "create_result_file(model, test_dataset, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XPU6sQWkIKaK",
        "outputId": "ed74f017-3f9d-45c8-d164-b8f6018d32f7"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_57eea43c-544b-4317-aaa4-ee721eac7591\", \"result2.csv\", 1189250)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('result2.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
