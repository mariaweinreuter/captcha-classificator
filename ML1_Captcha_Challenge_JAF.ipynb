{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariaweinreuter/ml-captcha-classificator/blob/Leon/ML1_Captcha_Challenge_JAF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmDbxCbvwdli"
      },
      "source": [
        "# Machine Learning 1 - KIT\n",
        "\n",
        "In this exercise you will classify images taken from google's reCAPTCHA.\n",
        "<div>\n",
        "<img src=https://i.ds.at/LuvqbQ/rs:fill:1600:0/plain/2022/06/23/captcha.jpg width=\"300\">\n",
        "<div>\n",
        "\n",
        "reCAPTCHA was created to differentiate between real humans and computer porgrams. With the breakthrough of deep learning based methods, these tactics to differentiate between humans and machines no longer work. Computer programs nowadays are perfectly able to solve classic captchas.\n",
        "\n",
        "This notebook shows the initial steps to load the datasets, create a dummy classifier and use the classifier to create the resulting file, which you will upload for grading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9uZJXP_Op49"
      },
      "source": [
        "## Your Task\n",
        "\n",
        "\n",
        "\n",
        "*   Split the labeled Data into sensible training and validation datasets\n",
        "*   Train a model to classify the training data\n",
        "*   Evaluate the model on your validation data\n",
        "*   If you think your model has a high accuracy, and is generalized well, predict the classes of the images from the testdataset and upload the results.csv at https://kit-ml1.streamlitapp.com/\n",
        "* You will get Bonus Points in the exam if your accuracy on test-data is high enough\n",
        "\n",
        "## Learning Goals\n",
        "\n",
        "* How to preprocess data\n",
        "* How to split data to prevent over- and underfitting\n",
        "* How to train a model\n",
        "* How to improve accuracy on unlabeled data\n",
        "    * Model architecture\n",
        "    * Model initialization\n",
        "    * Optimizer\n",
        "    * Batch size\n",
        "    * Image Augmentation\n",
        "    * ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y78r0RhwZDl"
      },
      "outputs": [],
      "source": [
        "## Lots of imports\n",
        "import matplotlib.pyplot as plt # for visualization\n",
        "import numpy as np #for fast calculation of matrices and vectors\n",
        "import os # for reading and writing files\n",
        "import pandas as pd # for creating dataframes and later saving the .csv\n",
        "import torch # PyTorch\n",
        "import torch.nn as nn # layers of neural netowrk\n",
        "from torch.utils.data import random_split, DataLoader, ConcatDataset # Creating datasets\n",
        "import torchvision # the part of PyTorch which is used for images\n",
        "from torchvision import datasets, models, transforms # used for loading images\n",
        "\n",
        "\n",
        "torch.manual_seed(3407) # makes your code deterministic so you can compare your results\n",
        "np.random.seed(3407)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vj9ZHV00J-A"
      },
      "source": [
        "Download the two .zip files that are available on ilias.\n",
        "You should have `train_val.zip` and `test.zip`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoNlywJmr-a8"
      },
      "source": [
        "## Using Google Colab but no Google Drive\n",
        "\n",
        "Upload both files, unzip them. This method has the disadvantage that you have to do it every time you reload the Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmB0msZRsN27"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "!unzip test.zip\n",
        "!unzip train_val.zip\n",
        "# Where is the folder test_data and train_val_data. ./ says it is in the same folder as this jupyter notebook\n",
        "root = \"./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5omXpcUyZQlS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDxxuANO3T9t"
      },
      "source": [
        "\n",
        "## Using Google Colab and Google Drive\n",
        "\n",
        "\n",
        "* Upload both files (drag and drop) to your free google drive account https://drive.google.com/drive/my-drive\n",
        "* On the left press the folder (Dateien) Symbol.\n",
        "* Then press the *Mount drive/ Drive bereitstellen* button which has the google drive symbol (triangle)\n",
        "* Allow access to your google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms3xywX90JJn"
      },
      "outputs": [],
      "source": [
        "## If you did this correctly you should see here \"drive\" and \"sample_data\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2sNQB4i5pXN"
      },
      "source": [
        "Unzip the files in your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMiJA8Kk12ye"
      },
      "outputs": [],
      "source": [
        "!unzip drive/MyDrive/train_val.zip -d drive/MyDrive/\n",
        "!unzip drive/MyDrive/test.zip -d drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPypPkR5raX3"
      },
      "source": [
        "This should have created the folders train_val_data and test_data in your google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdq6LUf9UrJq"
      },
      "outputs": [],
      "source": [
        "root = \"./drive/MyDrive/\" # where are these folders located?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRmi5t6J6hKj"
      },
      "source": [
        "## Using local Jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmgcV9jT6j_m"
      },
      "source": [
        "* Download both .zip files from Ilias\n",
        "* Extract them\n",
        "* Put this notebook .ipynb in the folder that also contains the folders `test_data` and `train_val_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSNXB7Iy43iI"
      },
      "outputs": [],
      "source": [
        "# Where is the folder test_data and train_val_data. ./ says it is in the same folder as this jupyter notebook\n",
        "root = \"./\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkQiqAFiOXvg"
      },
      "source": [
        "Now we have to create Datasets from these folders.\n",
        "\n",
        "For the train_val folder the images are sorted into their correct class folder.\n",
        "For the test folder we don't know the correct classes.\n",
        "\n",
        "We will use ImageFolder Datasets from  [PyTorch](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder)\n",
        "\n",
        "Each Image Folder uses [transforms](https://pytorch.org/vision/stable/transforms.html) to augment the image and create a tensor out of it.\n",
        "\n",
        "Some initial transforms are given. You are allowed (and probably should) add more transformations or modify the existing ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J33shogX4mk8"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(120), # makes that every image has size 120*120 # you can choose different resolutions\n",
        "    # you can add more augmentations here\n",
        "    transforms.ToTensor(), # creates a tensor out of Image\n",
        "])\n",
        "\n",
        "# transformation 1: just cropping the original data\n",
        "train_val_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(120), # should be the same resolution as the test_transform\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJUuUjjWSiUP"
      },
      "source": [
        "Now we use these transformations to create our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZsrmX6JSl7x"
      },
      "outputs": [],
      "source": [
        "# transform the dataset with the transformations defined above\n",
        "train_folder = root + \"train_val_data/\"\n",
        "train_val_dataset = datasets.ImageFolder(train_folder, transform=train_val_transform)\n",
        "\n",
        "train_val_length = len(train_val_dataset)\n",
        "print(f\"The trainval dataset contains {train_val_length} labeled images\") # should be 3000\n",
        "\n",
        "\n",
        "test_folder = root + \"test_data/\"\n",
        "test_dataset = datasets.ImageFolder(test_folder, transform=test_transform)\n",
        "\n",
        "print(f\"The test dataset contains {len(test_dataset)} unlabeled images\") # should be 8730"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivk5Wbb5aWl3"
      },
      "source": [
        "Let's look at the first element of our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta0Av02tacHE"
      },
      "outputs": [],
      "source": [
        "first_elem = train_val_dataset.__getitem__(0)\n",
        "print(f\"An element of a dataset contains {len(first_elem)} fields. (should be 2). The first field is an image, the second value is its corresponding label \\n\")\n",
        "\n",
        "# the first index should be a tensor representation of an image\n",
        "print(\"tensor of first image\", first_elem[0], \"\\n\")\n",
        "\n",
        "print(\"image should be of shape 3,size,size: \", first_elem[0].shape)\n",
        "\n",
        "# convert tensor back to a PIL image and visualize it with display()\n",
        "display(transforms.ToPILImage()(first_elem[0]))\n",
        "# Each folder is a class\n",
        "classes = train_val_dataset.classes\n",
        "print(\"We have the follwing classes\", classes)\n",
        "\n",
        "# Each classname is assigned an index\n",
        "class_names = train_val_dataset.class_to_idx\n",
        "print(\"Each class gets an index value\", class_names)\n",
        "\n",
        "# the second index is the numerical value of our label taken from the folder name\n",
        "print(f\"For the first image we have index {first_elem[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62cNKyQVI3J"
      },
      "source": [
        "Split this dataset into a training set and a validation set.\n",
        "For this you can use [random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split)\n",
        "\n",
        "In this example we will use 10% of the dataset for training and 90% for validation. You should change this percentage to a reasonable value\n",
        "Remember overfitting and underfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmQuM-oUTic2"
      },
      "outputs": [],
      "source": [
        "train_percentage = 0.9 # how much of the dataset should be used for training --> change this value\n",
        "\n",
        "no_train_images = int(train_val_length * train_percentage)\n",
        "no_valid_images = train_val_length - no_train_images\n",
        "\n",
        "train_dataset, valid_dataset = random_split(dataset=train_val_dataset, lengths=[no_train_images ,no_valid_images], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "print(f\"we divided the {len(train_val_dataset)} labeled images into {len(train_dataset)} training images and {len(valid_dataset)} validation images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6x-uDRmXkdj"
      },
      "source": [
        "Let's Create [Dataloaders](https://pytorch.org/docs/stable/data.html)\n",
        "Dataloaders loads our data in batches and faster so out training speed increases.\n",
        "\n",
        "The important arguments of the Dataloader are `dataset, batch_size, shuffle and  num_workers`\n",
        "We are already giving the argument for dataset, you should choose fitting values for the other arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMcLxoWqYbIs"
      },
      "source": [
        "Let's create dataloaders for train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeR2zawMWvBI"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True) # You are free to add values for other arguments\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2sCL-4JZ7Gb"
      },
      "source": [
        "Lets visualize images from the train loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Z2ooIKZpIL"
      },
      "outputs": [],
      "source": [
        "def vis_batch(loader):\n",
        "    def show(inp, label):\n",
        "        fig = plt.gcf()\n",
        "        plt.imshow(inp.permute(1,2,0))\n",
        "        plt.title(label)\n",
        "\n",
        "    for batch_inputs, labels in loader:\n",
        "        grid = torchvision.utils.make_grid(batch_inputs)\n",
        "        show(grid, label=[classes[int(labels[x])] for x in range(len(labels))])\n",
        "        break\n",
        "vis_batch(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPdTFYxFelMA"
      },
      "source": [
        "Correct model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70Z4yapJexA2"
      },
      "outputs": [],
      "source": [
        "# ResNet18 model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# define number of training epochs and the data iterator\n",
        "num_epochs = 7\n",
        "\n",
        "# Loading the pretrained Inception v3 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freezing all layers\n",
        "for param in model.parameters():\n",
        "    param.requiresGrad = False\n",
        "\n",
        "# Replacing the last layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 12)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=0.001)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # Loop over the data iterator, and feed the inputs and labels to the model\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the training process\n",
        "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "               .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U9Ort7tfDnE"
      },
      "source": [
        "You should use a different model.\n",
        "Also you should now train your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSe0MAsUUHpF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as1CpFAKF1mB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0jPOhfeUVST"
      },
      "source": [
        "The following method should not be changed. It predicts the classes for each image in the test dataset and stores them in a .csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVC2pt6NfDO-"
      },
      "outputs": [],
      "source": [
        "def create_result_file(model, test_dataset, classes): # DO NOT CHANGE THIS METHOD\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    keys = [\"ImageName\", *classes]\n",
        "\n",
        "    prediction_dict = {key: [] for key in keys}\n",
        "    names = test_dataset.imgs\n",
        "    model.to(device)\n",
        "    model.eval() # set model to evaluation mode.\n",
        "    for i in range(len(test_dataset)):\n",
        "        input = test_dataset.__getitem__(i)\n",
        "        input = input[0].to(device).unsqueeze(0) # take image tensor and add batch dimension\n",
        "        with torch.no_grad(): # don't calculate gradients\n",
        "            outputs = model(input).cpu().squeeze().numpy() # get prediction for input image\n",
        "            prediction_dict[\"ImageName\"].append(os.path.basename(names[i][0])) # save image name\n",
        "            for class_idx, class_name in enumerate(classes): # save prediction for each class\n",
        "                prediction_dict[class_name].append(outputs[class_idx])\n",
        "\n",
        "    df = pd.DataFrame.from_dict(prediction_dict) # convert list into pandas dataframe\n",
        "    df.to_csv(\"result.csv\", index=False) # save dataframe as .csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjKnVEpwhNow"
      },
      "source": [
        "After training we can execute the\n",
        "`\n",
        "create_result_file(model, test_dataset, classes) method\n",
        "`\n",
        "In this given code we skip training and use our untrained model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUjjo1_PdcVf"
      },
      "outputs": [],
      "source": [
        "create_result_file(model, test_dataset, classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hier wurde eine aenderung gemacht"
      ],
      "metadata": {
        "id": "ZdOIVQkiE36y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIEDO_xdj5DP"
      },
      "source": [
        "If you use Google colab, press the button `update/aktualisieren`\n",
        "<div>\n",
        "<img src=https://git.scc.kit.edu/vy9905/ml2images/-/raw/main/UpdateColab.jpg width=\"300\">\n",
        "<div>\n",
        "You should see that the file result.csv was created. You can now download this file and upload it at\n",
        "\n",
        "https://kit-ml1.streamlitapp.com/\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}